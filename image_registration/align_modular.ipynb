{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Align images using keypoints and homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% load images\n",
    "import os\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider\n",
    "# import ipywidgets as widgets\n",
    "# from IPython.display import display\n",
    "\n",
    "# Directory containing the images\n",
    "directory = os.path.join('data', 'beads')\n",
    "\n",
    "# List to hold image paths\n",
    "image_paths = []\n",
    "\n",
    "# Load the image paths\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.tif'):\n",
    "        image_paths.append(os.path.join(directory, filename))\n",
    "\n",
    "# Ensure there are images in the directory\n",
    "if len(image_paths) == 0:\n",
    "    raise ValueError(\"No TIFF images found in the directory.\")\n",
    "\n",
    "# Function to load the z-stack from a TIFF file\n",
    "def load_z_stack(image_path):\n",
    "    with tiff.TiffFile(image_path) as tif:\n",
    "        z_stack = [page.asarray() for page in tif.pages]\n",
    "    return z_stack\n",
    "\n",
    "z_stacks = [load_z_stack(image_path) for image_path in image_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_compute_keypoints(image, detector):\n",
    "    keypoints, descriptors = detector.detectAndCompute(image, None)\n",
    "    return keypoints, descriptors\n",
    "\n",
    "\n",
    "def match_descriptors(descriptors1, descriptors2, distance_metric=cv2.NORM_L2, cross_check=True):\n",
    "    bf = cv2.BFMatcher(distance_metric, crossCheck=cross_check)\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    return matches\n",
    "\n",
    "\n",
    "def filter_matches_by_distance(matches, keypoints1, keypoints2, max_distance=100):\n",
    "    filtered_matches = []\n",
    "    for match in matches:\n",
    "        pt1 = keypoints1[match.queryIdx].pt\n",
    "        pt2 = keypoints2[match.trainIdx].pt\n",
    "        distance = np.linalg.norm(np.array(pt1) - np.array(pt2))\n",
    "        if distance < max_distance:\n",
    "            filtered_matches.append(match)\n",
    "    return filtered_matches\n",
    "\n",
    "\n",
    "def compute_homography(filtered_matches, keypoints1, keypoints2):\n",
    "    if len(filtered_matches) >= 4:\n",
    "        src_pts = np.float32([keypoints1[m.queryIdx].pt for m in filtered_matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in filtered_matches]).reshape(-1, 1, 2)\n",
    "        H, mask = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)\n",
    "        return H, mask\n",
    "    else:\n",
    "        print(\"Not enough matches are found to compute a reliable homography.\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def warp_image(image, H, shape):\n",
    "    return cv2.warpPerspective(image, H, shape)\n",
    "\n",
    "\n",
    "def visualize_keypoints_and_matches(image1, keypoints1, image2, keypoints2, matches, title):\n",
    "    img_matches = cv2.drawMatches(image1, keypoints1, image2, keypoints2, matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.title(title)\n",
    "    plt.imshow(img_matches)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_warped_image(image1, image2, warped_image):\n",
    "    plt.figure(figsize=(18, 6))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title('Plane 1 Slice 1')\n",
    "    plt.imshow(image1, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title('Plane 2 Slice 1')\n",
    "    plt.imshow(image2, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title('Warped Plane 2 Slice 1')\n",
    "    plt.imshow(warped_image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def overlay_and_difference_images(image1, warped_image):\n",
    "    overlay = cv2.addWeighted(image1, 0.5, warped_image, 0.5, 0)\n",
    "    difference = cv2.absdiff(image1, warped_image)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('Overlay of Plane 1 and Warped Plane 2')\n",
    "    plt.imshow(overlay, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title('Difference between Plane 1 and Warped Plane 2')\n",
    "    plt.imshow(difference, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def calculate_keypoint_displacement(filtered_matches, keypoints1, keypoints2, H):\n",
    "    src_pts = np.float32([keypoints1[m.queryIdx].pt for m in filtered_matches]).reshape(-1, 2)\n",
    "    dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in filtered_matches]).reshape(-1, 2)\n",
    "    warped_keypoints = cv2.perspectiveTransform(dst_pts.reshape(-1, 1, 2), H).reshape(-1, 2)\n",
    "    displacement = np.linalg.norm(warped_keypoints - src_pts, axis=1)\n",
    "\n",
    "    print('Displacement of keypoints after warping:')\n",
    "    for i, d in enumerate(displacement):\n",
    "        print(f'Keypoint {i}: Displacement = {d:.2f} pixels')\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(src_pts[:, 0], src_pts[:, 1], color='red', label='Original Keypoints')\n",
    "    plt.scatter(warped_keypoints[:, 0], warped_keypoints[:, 1], color='blue', label='Warped Keypoints', alpha=0.6)\n",
    "    plt.legend()\n",
    "    plt.title('Keypoint Displacement due to Warping')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main(plane1_slice1, plane2_slice1):\n",
    "    # Initialize SIFT detector\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints1, descriptors1 = detect_and_compute_keypoints(plane1_slice1, sift)\n",
    "    keypoints2, descriptors2 = detect_and_compute_keypoints(plane2_slice1, sift)\n",
    "\n",
    "    # Match descriptors\n",
    "    matches = match_descriptors(descriptors1, descriptors2)\n",
    "\n",
    "    # # Visualize initial matches\n",
    "    # visualize_keypoints_and_matches(plane1_slice1, keypoints1, plane2_slice1, keypoints2, matches, 'Matches between Plane 1 Slice 1 and Plane 2 Slice 1 using SIFT')\n",
    "\n",
    "    # Filter matches by distance\n",
    "    filtered_matches = filter_matches_by_distance(matches, keypoints1, keypoints2, max_distance=100)\n",
    "\n",
    "    print(f'Filtered matches within distance threshold: {len(filtered_matches)}')\n",
    "\n",
    "    # Visualize filtered matches\n",
    "    visualize_keypoints_and_matches(plane1_slice1, keypoints1, plane2_slice1, keypoints2, filtered_matches, 'Filtered Matches between Plane 1 and Plane 2 (with Distance Filter)')\n",
    "\n",
    "    # Compute homography and warp the second image\n",
    "    H, _ = compute_homography(filtered_matches, keypoints1, keypoints2)\n",
    "    if H is not None:\n",
    "        height, width = plane1_slice1.shape\n",
    "        warped_plane2 = warp_image(plane2_slice1, H, (width, height))\n",
    "\n",
    "        # Visualize the aligned images\n",
    "        visualize_warped_image(plane1_slice1, plane2_slice1, warped_plane2)\n",
    "\n",
    "        # Visualize overlay and difference\n",
    "        overlay_and_difference_images(plane1_slice1, warped_plane2)\n",
    "\n",
    "        # Calculate and visualize keypoint displacement\n",
    "        calculate_keypoint_displacement(filtered_matches, keypoints1, keypoints2, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_convert_to_uint8(image1, image2):\n",
    "    \"\"\"\n",
    "    Normalize images to the range [0, 255] and convert them to uint8.\n",
    "\n",
    "    Args:\n",
    "        image1 (numpy.ndarray): The first image to process.\n",
    "        image2 (numpy.ndarray): The second image to process.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Two images, normalized and converted to uint8.\n",
    "    \"\"\"\n",
    "    # Normalize the images to the range [0, 255]\n",
    "    image1_normalized = cv2.normalize(image1, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    image2_normalized = cv2.normalize(image2, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "    # Convert the images to uint8\n",
    "    image1_uint8 = image1_normalized.astype(np.uint8)\n",
    "    image2_uint8 = image2_normalized.astype(np.uint8)\n",
    "\n",
    "    return image1_uint8, image2_uint8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_convert_to_uint8_single(image):\n",
    "    \"\"\"\n",
    "    Normalize an image to the range [0, 255] and convert it to uint8.\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): The image to process.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The image, normalized and converted to uint8.\n",
    "    \"\"\"\n",
    "    # Normalize the image to the range [0, 255]\n",
    "    image_normalized = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "    # Convert the image to uint8\n",
    "    image_uint8 = image_normalized.astype(np.uint8)\n",
    "\n",
    "    return image_uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane1_slice1 = z_stacks[0][0]\n",
    "plane2_slice1 = z_stacks[1][0]\n",
    "plane1_slice1, plane2_slice1 = normalize_and_convert_to_uint8(plane1_slice1, plane2_slice1)\n",
    "\n",
    "# Run the main function\n",
    "main(plane1_slice1, plane2_slice1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(plane1_slice1, plane2_slice1):\n",
    "    # Initialize SIFT detector\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints1, descriptors1 = detect_and_compute_keypoints(plane1_slice1, sift)\n",
    "    keypoints2, descriptors2 = detect_and_compute_keypoints(plane2_slice1, sift)\n",
    "\n",
    "    # Match descriptors\n",
    "    matches = match_descriptors(descriptors1, descriptors2)\n",
    "\n",
    "    # Filter matches by distance\n",
    "    filtered_matches = filter_matches_by_distance(matches, keypoints1, keypoints2, max_distance=100)\n",
    "\n",
    "    print(f'Filtered matches within distance threshold: {len(filtered_matches)}')\n",
    "\n",
    "    # Visualize filtered matches\n",
    "    visualize_keypoints_and_matches(plane1_slice1, keypoints1, plane2_slice1, keypoints2, filtered_matches, 'Filtered Matches between Plane 1 and Plane 2 (with Distance Filter)')\n",
    "\n",
    "    # Compute homography and warp the second image\n",
    "    H, _ = compute_homography(filtered_matches, keypoints1, keypoints2)\n",
    "    if H is not None:\n",
    "        height, width = plane1_slice1.shape\n",
    "        warped_plane2 = warp_image(plane2_slice1, H, (width, height))\n",
    "\n",
    "        # Visualize the aligned images\n",
    "        visualize_warped_image(plane1_slice1, plane2_slice1, warped_plane2)\n",
    "\n",
    "        # Visualize overlay and difference\n",
    "        overlay_and_difference_images(plane1_slice1, warped_plane2)\n",
    "\n",
    "        # Calculate and visualize keypoint displacement\n",
    "        calculate_keypoint_displacement(filtered_matches, keypoints1, keypoints2, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(plane1_slice1, plane2_slice1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_and_return_transform(plane1_slice1, plane2_slice1):\n",
    "    \"\"\"\n",
    "    Process the images to detect keypoints, match descriptors, filter matches, \n",
    "    compute homography, and warp the second image.\n",
    "\n",
    "    Parameters:\n",
    "    plane1_slice1 (numpy.ndarray): The first image.\n",
    "    plane2_slice1 (numpy.ndarray): The second image.\n",
    "\n",
    "    Returns:\n",
    "    tuple: (filtered_matches, keypoints1, keypoints2, H, warped_plane2)\n",
    "        - filtered_matches: The list of filtered matches.\n",
    "        - keypoints1: Keypoints detected in the first image.\n",
    "        - keypoints2: Keypoints detected in the second image.\n",
    "        - H: The computed homography matrix.\n",
    "        - warped_plane2: The second image after warping with the homography.\n",
    "    \"\"\"\n",
    "    # Initialize SIFT detector\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints1, descriptors1 = detect_and_compute_keypoints(plane1_slice1, sift)\n",
    "    keypoints2, descriptors2 = detect_and_compute_keypoints(plane2_slice1, sift)\n",
    "\n",
    "    # Match descriptors\n",
    "    matches = match_descriptors(descriptors1, descriptors2)\n",
    "\n",
    "    # Filter matches by distance\n",
    "    filtered_matches = filter_matches_by_distance(matches, keypoints1, keypoints2, max_distance=10)\n",
    "\n",
    "    print(f'Filtered matches within distance threshold: {len(filtered_matches)}')\n",
    "\n",
    "    # Compute homography\n",
    "    H, _ = compute_homography(filtered_matches, keypoints1, keypoints2)\n",
    "\n",
    "    # Warp the second image if homography is computed\n",
    "    warped_plane2 = None\n",
    "    if H is not None:\n",
    "        height, width = plane1_slice1.shape\n",
    "        warped_plane2 = warp_image(plane2_slice1, H, (width, height))\n",
    "\n",
    "    return warped_plane2, filtered_matches, keypoints1, keypoints2, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plane1_slice1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m warped_plane2, filtered_matches, keypoints1, keypoints2, H \u001b[38;5;241m=\u001b[39m align_and_return_transform(\u001b[43mplane1_slice1\u001b[49m, plane2_slice1)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plane1_slice1' is not defined"
     ]
    }
   ],
   "source": [
    "warped_plane2, filtered_matches, keypoints1, keypoints2, H = align_and_return_transform(plane1_slice1, plane2_slice1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_stacks(plane1_stack, plane2_stack, plane3_stack):\n",
    "    \"\"\"Align the 1st and 3rd planes of image stacks to the 2nd plane and return alignment info.\"\"\"\n",
    "    aligned_plane1_stack = []\n",
    "    aligned_plane3_stack = []\n",
    "\n",
    "    all_info_plane1 = []\n",
    "    all_info_plane3 = []\n",
    "\n",
    "    for i in range(len(plane2_stack)):\n",
    "        # Normalize and convert each slice to uint8\n",
    "        plane1_slice = normalize_and_convert_to_uint8_single(plane1_stack[i])\n",
    "        plane2_slice = normalize_and_convert_to_uint8_single(plane2_stack[i])\n",
    "        plane3_slice = normalize_and_convert_to_uint8_single(plane3_stack[i])\n",
    "\n",
    "        # Align the 1st slice to the 2nd\n",
    "        aligned_plane1_slice, filtered_matches1, keypoints1_1, keypoints2_1, H1 = align_and_return_transform(plane2_slice, plane1_slice)\n",
    "        aligned_plane3_slice, filtered_matches3, keypoints1_3, keypoints2_3, H3 = align_and_return_transform(plane2_slice, plane3_slice)\n",
    "\n",
    "        if aligned_plane1_slice is not None:\n",
    "            aligned_plane1_stack.append(aligned_plane1_slice)\n",
    "        else:\n",
    "            print(f\"Warning: Alignment failed for slice {i} in Plane 1.\")\n",
    "        \n",
    "        if aligned_plane3_slice is not None:\n",
    "            aligned_plane3_stack.append(aligned_plane3_slice)\n",
    "        else:\n",
    "            print(f\"Warning: Alignment failed for slice {i} in Plane 3.\")\n",
    "\n",
    "        # Store alignment information\n",
    "        all_info_plane1.append((filtered_matches1, keypoints1_1, keypoints2_1, H1))\n",
    "        all_info_plane3.append((filtered_matches3, keypoints1_3, keypoints2_3, H3))\n",
    "        \n",
    "        # break\n",
    "\n",
    "    return (np.array(aligned_plane1_stack), plane2_stack, np.array(aligned_plane3_stack)), all_info_plane1, all_info_plane3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_single_plane(plane_slice, ref_slice):\n",
    "    \"\"\"Align a single plane slice to a reference slice and return alignment info.\"\"\"\n",
    "    # Normalize and convert slices to uint8\n",
    "    plane_slice = normalize_and_convert_to_uint8_single(plane_slice)\n",
    "    ref_slice = normalize_and_convert_to_uint8_single(ref_slice)\n",
    "\n",
    "    # Align the plane slice to the reference slice and return the transformation info\n",
    "    aligned_slice, filtered_matches, keypoints1, keypoints2, H = align_and_return_transform(ref_slice, plane_slice)\n",
    "    \n",
    "    if aligned_slice is None:\n",
    "        aligned_slice = plane_slice\n",
    "\n",
    "    return aligned_slice, (filtered_matches, keypoints1, keypoints2, H)\n",
    "\n",
    "def align_stacks(plane1_stack, plane2_stack, plane3_stack):\n",
    "    \"\"\"Align the 1st and 3rd planes of image stacks to the 2nd plane and return alignment info.\"\"\"\n",
    "    aligned_plane1_stack, aligned_plane3_stack = [], []\n",
    "    all_info_plane1, all_info_plane3 = [], []\n",
    "\n",
    "    for i in range(len(plane2_stack)):\n",
    "        # Align slices for Plane 1 and Plane 3 to Plane 2\n",
    "        aligned_plane1_slice, info_plane1 = align_single_plane(plane1_stack[i], plane2_stack[i])\n",
    "        aligned_plane3_slice, info_plane3 = align_single_plane(plane3_stack[i], plane2_stack[i])\n",
    "\n",
    "        # Store the aligned slices if alignment succeeded\n",
    "        if aligned_plane1_slice is not None:\n",
    "            aligned_plane1_stack.append(aligned_plane1_slice)\n",
    "        else:\n",
    "            print(f\"Warning: Alignment failed for slice {i} in Plane 1.\")\n",
    "        \n",
    "        if aligned_plane3_slice is not None:\n",
    "            aligned_plane3_stack.append(aligned_plane3_slice)\n",
    "        else:\n",
    "            print(f\"Warning: Alignment failed for slice {i} in Plane 3.\")\n",
    "\n",
    "        # Store alignment information\n",
    "        all_info_plane1.append(info_plane1)\n",
    "        all_info_plane3.append(info_plane3)\n",
    "\n",
    "    return (\n",
    "        (np.array(aligned_plane1_stack), plane2_stack, np.array(aligned_plane3_stack)),\n",
    "        all_info_plane1,\n",
    "        all_info_plane3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered matches within distance threshold: 7\n",
      "Filtered matches within distance threshold: 6\n",
      "Filtered matches within distance threshold: 7\n",
      "Filtered matches within distance threshold: 7\n",
      "Filtered matches within distance threshold: 9\n",
      "Filtered matches within distance threshold: 5\n",
      "Filtered matches within distance threshold: 13\n",
      "Filtered matches within distance threshold: 4\n",
      "Filtered matches within distance threshold: 12\n",
      "Filtered matches within distance threshold: 4\n",
      "Filtered matches within distance threshold: 12\n",
      "Filtered matches within distance threshold: 6\n",
      "Filtered matches within distance threshold: 13\n",
      "Filtered matches within distance threshold: 5\n",
      "Filtered matches within distance threshold: 16\n",
      "Filtered matches within distance threshold: 7\n",
      "Filtered matches within distance threshold: 14\n",
      "Filtered matches within distance threshold: 6\n",
      "Filtered matches within distance threshold: 20\n",
      "Filtered matches within distance threshold: 8\n",
      "Filtered matches within distance threshold: 20\n",
      "Filtered matches within distance threshold: 8\n",
      "Filtered matches within distance threshold: 20\n",
      "Filtered matches within distance threshold: 11\n",
      "Filtered matches within distance threshold: 16\n",
      "Filtered matches within distance threshold: 13\n",
      "Filtered matches within distance threshold: 22\n",
      "Filtered matches within distance threshold: 8\n",
      "Filtered matches within distance threshold: 29\n",
      "Filtered matches within distance threshold: 11\n",
      "Filtered matches within distance threshold: 27\n",
      "Filtered matches within distance threshold: 11\n",
      "Filtered matches within distance threshold: 44\n",
      "Filtered matches within distance threshold: 13\n",
      "Filtered matches within distance threshold: 63\n",
      "Filtered matches within distance threshold: 12\n",
      "Filtered matches within distance threshold: 84\n",
      "Filtered matches within distance threshold: 11\n",
      "Filtered matches within distance threshold: 111\n",
      "Filtered matches within distance threshold: 11\n",
      "Filtered matches within distance threshold: 156\n",
      "Filtered matches within distance threshold: 9\n",
      "Filtered matches within distance threshold: 200\n",
      "Filtered matches within distance threshold: 12\n",
      "Filtered matches within distance threshold: 246\n",
      "Filtered matches within distance threshold: 10\n",
      "Filtered matches within distance threshold: 307\n",
      "Filtered matches within distance threshold: 19\n",
      "Filtered matches within distance threshold: 338\n",
      "Filtered matches within distance threshold: 25\n",
      "Filtered matches within distance threshold: 393\n",
      "Filtered matches within distance threshold: 48\n",
      "Filtered matches within distance threshold: 417\n",
      "Filtered matches within distance threshold: 72\n",
      "Filtered matches within distance threshold: 396\n",
      "Filtered matches within distance threshold: 90\n",
      "Filtered matches within distance threshold: 372\n",
      "Filtered matches within distance threshold: 154\n",
      "Filtered matches within distance threshold: 225\n",
      "Filtered matches within distance threshold: 213\n",
      "Filtered matches within distance threshold: 117\n",
      "Filtered matches within distance threshold: 268\n",
      "Filtered matches within distance threshold: 62\n",
      "Filtered matches within distance threshold: 334\n",
      "Filtered matches within distance threshold: 45\n",
      "Filtered matches within distance threshold: 418\n",
      "Filtered matches within distance threshold: 44\n",
      "Filtered matches within distance threshold: 434\n",
      "Filtered matches within distance threshold: 44\n",
      "Filtered matches within distance threshold: 431\n",
      "Filtered matches within distance threshold: 40\n",
      "Filtered matches within distance threshold: 396\n",
      "Filtered matches within distance threshold: 39\n",
      "Filtered matches within distance threshold: 276\n",
      "Filtered matches within distance threshold: 38\n",
      "Filtered matches within distance threshold: 135\n",
      "Filtered matches within distance threshold: 43\n",
      "Filtered matches within distance threshold: 65\n",
      "Filtered matches within distance threshold: 41\n",
      "Filtered matches within distance threshold: 44\n",
      "Filtered matches within distance threshold: 29\n",
      "Filtered matches within distance threshold: 38\n",
      "Filtered matches within distance threshold: 23\n",
      "Filtered matches within distance threshold: 40\n",
      "Filtered matches within distance threshold: 20\n",
      "Filtered matches within distance threshold: 38\n",
      "Filtered matches within distance threshold: 17\n",
      "Filtered matches within distance threshold: 27\n",
      "Filtered matches within distance threshold: 15\n",
      "Filtered matches within distance threshold: 26\n",
      "Filtered matches within distance threshold: 15\n",
      "Filtered matches within distance threshold: 36\n",
      "Filtered matches within distance threshold: 16\n",
      "Filtered matches within distance threshold: 32\n",
      "Filtered matches within distance threshold: 16\n",
      "Filtered matches within distance threshold: 32\n",
      "Filtered matches within distance threshold: 9\n",
      "Filtered matches within distance threshold: 22\n",
      "Filtered matches within distance threshold: 11\n",
      "Filtered matches within distance threshold: 18\n",
      "Filtered matches within distance threshold: 11\n",
      "Filtered matches within distance threshold: 22\n",
      "Filtered matches within distance threshold: 12\n",
      "Filtered matches within distance threshold: 18\n",
      "Filtered matches within distance threshold: 14\n",
      "Filtered matches within distance threshold: 14\n",
      "Filtered matches within distance threshold: 11\n",
      "Filtered matches within distance threshold: 11\n",
      "Filtered matches within distance threshold: 17\n",
      "Filtered matches within distance threshold: 13\n",
      "Filtered matches within distance threshold: 17\n",
      "Filtered matches within distance threshold: 11\n",
      "Filtered matches within distance threshold: 14\n",
      "Filtered matches within distance threshold: 7\n",
      "Filtered matches within distance threshold: 14\n",
      "Filtered matches within distance threshold: 7\n",
      "Filtered matches within distance threshold: 22\n",
      "Filtered matches within distance threshold: 11\n",
      "Filtered matches within distance threshold: 18\n",
      "Filtered matches within distance threshold: 14\n",
      "Filtered matches within distance threshold: 22\n",
      "Filtered matches within distance threshold: 14\n"
     ]
    }
   ],
   "source": [
    "plane1_stack = z_stacks[0]\n",
    "plane2_stack = z_stacks[1]\n",
    "plane3_stack = z_stacks[2]\n",
    "\n",
    "(aligned_plane1_stack, aligned_plane2_stack, aligned_plane3_stack), info_plane1, info_plane3 = align_stacks(plane1_stack, plane2_stack, plane3_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane2_stack[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(info_plane1)\n",
    "len(info_plane3[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display aligned images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf9404188acf4d44990f25754744f47a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Slice', max=60), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_slices_with_slider(z_stacks, image_paths):\n",
    "    \"\"\"\n",
    "    Display slices from multiple image stacks side by side with a slider to navigate through slices.\n",
    "\n",
    "    Parameters:\n",
    "    z_stacks (list of np.ndarray): List of image stacks, where each stack is a 3D NumPy array.\n",
    "    image_paths (list of str): List of file paths or names for the image stacks, used for labeling.\n",
    "\n",
    "    Usage:\n",
    "    display_slices_with_slider(z_stacks, image_paths)\n",
    "    \"\"\"\n",
    "    def show_slices(slice_num):\n",
    "        fig, axes = plt.subplots(1, len(z_stacks), figsize=(20, 8))\n",
    "        for ax, z_stack, image_path in zip(axes, z_stacks, image_paths):\n",
    "            ax.imshow(z_stack[slice_num], cmap='gray')\n",
    "            ax.set_title(f\"{os.path.basename(image_path)} - Slice {slice_num + 1}\")\n",
    "            ax.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    # Determine the number of slices (assuming all stacks have the same number of slices)\n",
    "    num_slices = len(z_stacks[0])\n",
    "\n",
    "    # Create a slider\n",
    "    slider = IntSlider(min=0, max=num_slices - 1, step=1, value=0, description='Slice')\n",
    "\n",
    "    # Display the slices side by side with the slider\n",
    "    interact(show_slices, slice_num=slider)\n",
    "\n",
    "z_stacks = [aligned_plane1_stack, aligned_plane2_stack, aligned_plane3_stack]\n",
    "display_slices_with_slider(z_stacks, image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align to offset slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_stacks_to_previous_slices(plane1_stack, plane2_stack, plane3_stack, offset=7):\n",
    "    \"\"\"Align each slice to the slice `offset` positions above it in the stack.\"\"\"\n",
    "    aligned_plane1_stack, aligned_plane3_stack = [], []\n",
    "    all_info_plane1, all_info_plane3 = [], []\n",
    "\n",
    "    for i in range(len(plane2_stack)):\n",
    "        if i >= offset and i < len(plane2_stack) - offset - 1:\n",
    "            # Align the current slice to the slice `offset` positions below and above it\n",
    "            aligned_plane1_slice, info_plane1 = align_single_plane(plane1_stack[i - offset], plane2_stack[i])\n",
    "            aligned_plane3_slice, info_plane3 = align_single_plane(plane3_stack[i + offset], plane2_stack[i])\n",
    "\n",
    "            # Store the aligned slices (or original slices if no alignment was possible)\n",
    "            aligned_plane1_stack.append(aligned_plane1_slice)\n",
    "            aligned_plane3_stack.append(aligned_plane3_slice)\n",
    "\n",
    "            # Store alignment information\n",
    "            all_info_plane1.append(info_plane1)\n",
    "            all_info_plane3.append(info_plane3)\n",
    "\n",
    "    return (\n",
    "        (np.array(aligned_plane1_stack), plane2_stack, np.array(aligned_plane3_stack)),\n",
    "        all_info_plane1,\n",
    "        all_info_plane3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(plane2_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered matches within distance threshold: 27\n",
      "Filtered matches within distance threshold: 24\n",
      "Filtered matches within distance threshold: 29\n",
      "Filtered matches within distance threshold: 25\n",
      "Filtered matches within distance threshold: 38\n",
      "Filtered matches within distance threshold: 35\n",
      "Filtered matches within distance threshold: 41\n",
      "Filtered matches within distance threshold: 38\n",
      "Filtered matches within distance threshold: 48\n",
      "Filtered matches within distance threshold: 43\n",
      "Filtered matches within distance threshold: 49\n",
      "Filtered matches within distance threshold: 43\n",
      "Filtered matches within distance threshold: 58\n",
      "Filtered matches within distance threshold: 50\n",
      "Filtered matches within distance threshold: 68\n",
      "Filtered matches within distance threshold: 51\n",
      "Filtered matches within distance threshold: 73\n",
      "Filtered matches within distance threshold: 59\n",
      "Filtered matches within distance threshold: 92\n",
      "Filtered matches within distance threshold: 61\n",
      "Filtered matches within distance threshold: 102\n",
      "Filtered matches within distance threshold: 71\n",
      "Filtered matches within distance threshold: 120\n",
      "Filtered matches within distance threshold: 92\n",
      "Filtered matches within distance threshold: 141\n",
      "Filtered matches within distance threshold: 111\n",
      "Filtered matches within distance threshold: 177\n",
      "Filtered matches within distance threshold: 150\n",
      "Filtered matches within distance threshold: 206\n",
      "Filtered matches within distance threshold: 191\n",
      "Filtered matches within distance threshold: 253\n",
      "Filtered matches within distance threshold: 247\n",
      "Filtered matches within distance threshold: 284\n",
      "Filtered matches within distance threshold: 286\n",
      "Filtered matches within distance threshold: 330\n",
      "Filtered matches within distance threshold: 340\n",
      "Filtered matches within distance threshold: 393\n",
      "Filtered matches within distance threshold: 413\n",
      "Filtered matches within distance threshold: 421\n",
      "Filtered matches within distance threshold: 482\n",
      "Filtered matches within distance threshold: 476\n",
      "Filtered matches within distance threshold: 518\n",
      "Filtered matches within distance threshold: 511\n",
      "Filtered matches within distance threshold: 587\n",
      "Filtered matches within distance threshold: 538\n",
      "Filtered matches within distance threshold: 605\n",
      "Filtered matches within distance threshold: 572\n",
      "Filtered matches within distance threshold: 638\n",
      "Filtered matches within distance threshold: 564\n",
      "Filtered matches within distance threshold: 661\n",
      "Filtered matches within distance threshold: 545\n",
      "Filtered matches within distance threshold: 667\n",
      "Filtered matches within distance threshold: 548\n",
      "Filtered matches within distance threshold: 636\n",
      "Filtered matches within distance threshold: 508\n",
      "Filtered matches within distance threshold: 608\n",
      "Filtered matches within distance threshold: 470\n",
      "Filtered matches within distance threshold: 542\n",
      "Filtered matches within distance threshold: 367\n",
      "Filtered matches within distance threshold: 446\n",
      "Filtered matches within distance threshold: 269\n",
      "Filtered matches within distance threshold: 323\n",
      "Filtered matches within distance threshold: 211\n",
      "Filtered matches within distance threshold: 242\n",
      "Filtered matches within distance threshold: 174\n",
      "Filtered matches within distance threshold: 197\n",
      "Filtered matches within distance threshold: 154\n",
      "Filtered matches within distance threshold: 176\n",
      "Filtered matches within distance threshold: 138\n",
      "Filtered matches within distance threshold: 154\n",
      "Filtered matches within distance threshold: 107\n",
      "Filtered matches within distance threshold: 129\n",
      "Filtered matches within distance threshold: 103\n",
      "Filtered matches within distance threshold: 116\n",
      "Filtered matches within distance threshold: 96\n",
      "Filtered matches within distance threshold: 115\n",
      "Filtered matches within distance threshold: 87\n",
      "Filtered matches within distance threshold: 101\n",
      "Filtered matches within distance threshold: 110\n",
      "Filtered matches within distance threshold: 108\n",
      "Filtered matches within distance threshold: 113\n",
      "Filtered matches within distance threshold: 115\n",
      "Filtered matches within distance threshold: 128\n",
      "Filtered matches within distance threshold: 152\n",
      "Filtered matches within distance threshold: 147\n",
      "Filtered matches within distance threshold: 144\n",
      "Filtered matches within distance threshold: 125\n",
      "Filtered matches within distance threshold: 135\n",
      "Filtered matches within distance threshold: 121\n",
      "Filtered matches within distance threshold: 119\n",
      "Filtered matches within distance threshold: 103\n",
      "Filtered matches within distance threshold: 119\n"
     ]
    }
   ],
   "source": [
    "(aligned_plane1_stack, aligned_plane2_stack, aligned_plane3_stack), info_plane1, info_plane3 = align_stacks_to_previous_slices(plane1_stack, plane2_stack, plane3_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7d5183199a4c8dadd00fc7abdde46e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Slice', max=45), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z_stacks = [aligned_plane1_stack, aligned_plane2_stack, aligned_plane3_stack]\n",
    "display_slices_with_slider(z_stacks, image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
